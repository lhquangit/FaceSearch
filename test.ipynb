{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01488c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef9042aa-44ad-430a-bff4-24dd0754c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc175ce-91e1-44c3-a0b8-4f7f92f668b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import cfg_mnet\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from models.retinaface import RetinaFace\n",
    "from utils.box_utils import decode, decode_landm\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841418c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee2ed7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from weights/mobilenet0.25_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:300\n",
      "Finished loading model!\n",
      "RetinaFace(\n",
      "  (body): IntermediateLayerGetter(\n",
      "    (stage1): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage3): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fpn): FPN(\n",
      "    (output1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (output2): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (output3): Sequential(\n",
      "      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (merge1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (merge2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh1): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh2): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh3): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ClassHead): ModuleList(\n",
      "    (0): ClassHead(\n",
      "      (conv1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): ClassHead(\n",
      "      (conv1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): ClassHead(\n",
      "      (conv1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (BboxHead): ModuleList(\n",
      "    (0): BboxHead(\n",
      "      (conv1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): BboxHead(\n",
      "      (conv1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): BboxHead(\n",
      "      (conv1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (LandmarkHead): ModuleList(\n",
      "    (0): LandmarkHead(\n",
      "      (conv1x1): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): LandmarkHead(\n",
      "      (conv1x1): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): LandmarkHead(\n",
      "      (conv1x1): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "cfg = None\n",
    "cfg = cfg_mnet\n",
    "\n",
    "# net and model\n",
    "net = RetinaFace(cfg=cfg, phase = 'test')\n",
    "net = load_model(net,pretrained_path='weights/mobilenet0.25_Final.pth', load_to_cpu=True)\n",
    "net.eval()\n",
    "print('Finished loading model!')\n",
    "print(net)\n",
    "cudnn.benchmark = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "sess = ort.InferenceSession(\"weights/webface_r50.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "# arcface = MobileFaceNet(embedding_size=512, out_h=7, out_w=7)\n",
    "# # arcface.load_state_dict(torch.load('weights/arcface_mobilefacenet.pth', map_location=torch.device('cpu')))\n",
    "# arcface = ResNet_50(input_size=(112,112))\n",
    "# arcface.load_state_dict(torch.load('weights/arcface_mobilefacenet.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "# arcface.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63f6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.9\n",
    "nms_threshold = 0.4\n",
    "keep_top_k = 750\n",
    "\n",
    "def predict_face(img_raw):\n",
    "    \n",
    "    img = np.float32(img_raw)\n",
    "    # if resize != 1:\n",
    "    #     img = cv2.resize(img, None, None, fx=resize, fy=resize, interpolation=cv2.INTER_LINEAR)\n",
    "    im_height, im_width, _ = img.shape\n",
    "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "    img -= (104, 117, 123)\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    scale = scale.to(device)\n",
    "\n",
    "    loc, conf, landms = net(img)  # forward pass\n",
    "    priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "    priors = priorbox.forward()\n",
    "    priors = priors.to(device)\n",
    "    prior_data = priors.data\n",
    "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    # boxes = boxes * scale / resize\n",
    "    boxes = boxes.cpu().numpy()\n",
    "    scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "    landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                           img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                           img.shape[3], img.shape[2]])\n",
    "    scale1 = scale1.to(device)\n",
    "    # landms = landms * scale1 / resize\n",
    "    landms = landms.cpu().numpy()\n",
    "\n",
    "    # ignore low scores\n",
    "    inds = np.where(scores > confidence_threshold)[0]\n",
    "    boxes = boxes[inds]\n",
    "    landms = landms[inds]\n",
    "    scores = scores[inds]\n",
    "\n",
    "    # keep top-K before NMS\n",
    "    # order = scores.argsort()[::-1][:args.top_k]\n",
    "    order = scores.argsort()[::-1]\n",
    "    boxes = boxes[order]\n",
    "    landms = landms[order]\n",
    "    scores = scores[order]\n",
    "\n",
    "    # do NMS\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(dets, nms_threshold)\n",
    "\n",
    "    dets = dets[keep, :]\n",
    "    landms = landms[keep]\n",
    "\n",
    "    # keep top-K faster NMS\n",
    "    dets = dets[:keep_top_k, :]\n",
    "    # landms = landms[:args.keep_top_k, :]\n",
    "\n",
    "    dets = np.concatenate((dets, landms), axis=1)\n",
    "    for k in range(dets.shape[0]):\n",
    "        xmin = int(dets[k, 0]*im_width)\n",
    "        ymin = int(dets[k, 1]*im_height)\n",
    "        xmax = int(dets[k, 2]*im_width)\n",
    "        ymax = int(dets[k, 3]*im_height)\n",
    "        score = dets[k, 4]\n",
    "        w = xmax - xmin + 1\n",
    "        h = ymax - ymin + 1\n",
    "    face_cv = img_raw[ymin:ymax,xmin:xmax]\n",
    "    bbox = [xmin, ymin, xmax, ymax, score]\n",
    "    face_cv = cv2.resize(face_cv,(112,112))\n",
    "    face = (face_cv.transpose(2, 0, 1).astype(np.float32)-127.5)/255\n",
    "#     face = torch.from_numpy(face).unsqueeze(0)\n",
    "#     face = torchvision.transforms.Resize((112,112))(face)\n",
    "#     emb = arcface(face)\n",
    "#     \n",
    "    emb = sess.run([label_name], {input_name: np.array([face]).astype(np.float32)})[0]\n",
    "    return bbox, face_cv, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ae7e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb45a1d4aa34fa4b87cf8561519aa37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder = 'datasets/rikai/'\n",
    "embs =[]\n",
    "ids = []\n",
    "\n",
    "for path in  tqdm(os.listdir(folder)):\n",
    "    img_path = folder+ path +'/'+os.listdir(folder+ path)[0]\n",
    "    \n",
    "#     print(img_path)\n",
    "    img_raw = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img_raw = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "    try:\n",
    "        bbox, face, emb = predict_face(img_raw)\n",
    "#         plt.imshow(face)\n",
    "#         plt.show()\n",
    "        embs.append(emb[0])\n",
    "        ids.append(path)\n",
    "    except:\n",
    "        pass\n",
    "embs = np.array(embs)\n",
    "ids = np.array(ids)\n",
    "np.save('embs/rikai_embs', embs)\n",
    "np.save('embs/rikai_ids', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c1d779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs= np.load('embs/rikai_embs.npy')\n",
    "ids= np.load('embs/rikai_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2f9bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def face_search(img_raw):\n",
    "    bbox, face, emb = predict_face(img_raw)\n",
    "    plt.imshow(face)\n",
    "    plt.show()\n",
    "    cos = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "    output = cosine_similarity(embs, emb.reshape(1,-1))\n",
    "    # print(output)\n",
    "    # path= ids[np.argmax(output)] \n",
    "    # score =output[np.argmax(output)]\n",
    "    names_kq = ids[np.flip(np.argsort(output.reshape(-1)))[:3]]\n",
    "    scores_kq = output[np.flip(np.argsort(output.reshape(-1)))[:3]]\n",
    "    print(names_kq, scores_kq)\n",
    "    kq=[]\n",
    "#     if scores_kq[0] >0.25:\n",
    "    for i,path in enumerate(names_kq):\n",
    "        img_path = folder+ path +'/'+os.listdir(folder+ path)[0]\n",
    "        img_raw = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img_raw = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "        img_raw = cv2.resize(img_raw,(480,640))\n",
    "        kq.append(img_raw)\n",
    "    return (names_kq[0], kq[0], names_kq[1], kq[1],names_kq[2], kq[2])\n",
    "    #         plt.imshow(img_raw)\n",
    "    #         plt.show()\n",
    "#             print(path, scores_kq[i][0])\n",
    "#             try:\n",
    "#                 bbox, face, emb = predict_face(img_raw)\n",
    "#                 plt.imshow(face)\n",
    "#                 plt.show()\n",
    "#             except:\n",
    "#                 pass\n",
    "#     else:\n",
    "#         return 'No Face Match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0590c4f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://192.168.1.26:8080/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://192.168.1.26:8080/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7f7dee3f9b70>, 'http://192.168.1.26:8080/', None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "demo = gr.Interface(fn=face_search, inputs=\"image\", outputs=[\"text\",\"image\",\"text\",\"image\",\"text\",\"image\"],)\n",
    "demo.launch(server_name = '192.168.1.26',server_port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fbbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
